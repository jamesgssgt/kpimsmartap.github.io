import asyncio
import random
import time
import json
import os
from datetime import datetime, timedelta
from fhirpy import AsyncFHIRClient
import urllib3

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

FHIR_SERVER_URL = "https://launch.smarthealthit.org/v/r4/fhir"
TOTAL_CASES = 300 
DAYS_BACK = 180

# Load env vars from .env.local manually
def load_env():
    try:
        with open('.env.local', 'r') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, val = line.strip().split('=', 1)
                    val = val.strip('"').strip("'")
                    os.environ[key] = val
        print("Env vars loaded from .env.local")
    except Exception as e:
        print(f"No .env.local found or error reading it: {e}")

load_env()

SUPABASE_URL = os.environ.get("NEXT_PUBLIC_SUPABASE_URL")
SUPABASE_KEY = os.environ.get("NEXT_PUBLIC_SUPABASE_ANON_KEY")

# å®šç¾©ä¸‰å®¶é†«é™¢æ¶æ§‹
HOSPITALS = [
    {"code": "TP_GEN", "name": "å°åŒ—ç¶œåˆé†«é™¢", "risk": 1.0},
    {"code": "NAT_MED", "name": "åœ‹ç«‹é†«å­¸ä¸­å¿ƒ", "risk": 1.2}, 
    {"code": "CITY_UN", "name": "å¸‚ç«‹è¯åˆé†«é™¢", "risk": 0.8}
]

DEPT_TEMPLATE = {
    "SURG": {"name": "å¤–ç§‘", "docs": ["åŠ‰", "å¼µ"]},
    "CARDIO": {"name": "å¿ƒè‡Ÿç§‘", "docs": ["å³", "è”¡"]},
    "ORTHO": {"name": "éª¨ç§‘", "docs": ["ç‹", "æ"]}
}

# Global list to store detailed records
KPI_DETAILS_BUFFER = []

def get_long_id():
    prefix = random.choice(['A', 'B', 'H', 'M'])
    ts = str(int(time.time() * 1000000))[-7:]
    rand = str(random.randint(1000, 9999))
    return f"{prefix}{ts}{rand}"

async def create_infrastructure(client):
    print("ğŸ¥ å»ºç«‹çµ„ç¹”èˆ‡å¸³è™Ÿç³»çµ±...")
    infra = {}
    auth_db = [] # ç”¨ä¾†å­˜å¸³è™Ÿè³‡è¨Š
    
    for hosp in HOSPITALS:
        h_code = hosp['code']
        infra[h_code] = {'risk': hosp['risk'], 'depts': []}
        
        # å»ºç«‹é†«é™¢æœ¬èº«çš„ Organization (ä½œç‚ºé™¢é•·å®¤æ¬Šé™ä¾æ“š)
        hosp_org_id = get_long_id()
        hosp_org = client.resource('Organization', id=hosp_org_id, name=hosp['name'], type=[{'text': 'Hospital'}])
        await hosp_org.save()
        
        # åŠ å…¥ Auth DB (é™¢é•·å¸³è™Ÿ)
        auth_db.append({
            "role": "hospital_admin",
            "name": f"{hosp['name']} (é™¢é•·å®¤)",
            "id": hosp_org_id,
            "hospitalName": hosp['name']
        })

        for d_code, d_info in DEPT_TEMPLATE.items():
            # å»ºç«‹ç§‘åˆ¥
            dept_org_id = get_long_id()
            full_dept_name = f"ã€{hosp['name']}ã€‘{d_info['name']}"
            org = client.resource('Organization', id=dept_org_id, name=full_dept_name, partOf={'reference': f"Organization/{hosp_org_id}"})
            await org.save()
            
            dept_docs = []
            for surname in d_info['docs']:
                doc_id = get_long_id()
                doc_name = f"{surname}é†«å¸«"
                full_name = f"{doc_name} ({hosp['name'][:2]})"
                
                prac = client.resource('Practitioner', id=doc_id, name=[{'text': full_name}])
                await prac.save()
                dept_docs.append(doc_id)
                
                # åŠ å…¥ Auth DB (é†«å¸«å¸³è™Ÿ)
                auth_db.append({
                    "role": "doctor",
                    "name": full_name,
                    "id": doc_id,
                    "hospitalName": hosp['name']
                })
            
            infra[h_code]['depts'].append({
                'org_id': dept_org_id,
                'org_name': full_dept_name,
                'dept_code': d_code,
                'doctors': dept_docs,
                'doc_names': {doc_id: f"{surname}é†«å¸«" for surname, doc_id in zip(d_info['docs'], dept_docs)}
            })
            
    return infra, auth_db

async def generate_case(client, infra, day_index):
    # Select random hospital, dept, doctor
    hosp_code = random.choice(list(infra.keys()))
    h_data = infra[hosp_code]
    hosp_name = next(h['name'] for h in HOSPITALS if h['code'] == hosp_code)
    
    dept = random.choice(h_data['depts'])
    dept_name = DEPT_TEMPLATE[dept['dept_code']]['name']
    
    doc_id = random.choice(dept['doctors'])
    doc_name = dept['doc_names'][doc_id] # Simple name like 'åŠ‰é†«å¸«'
    
    # Time and Risk
    today = datetime.now()
    case_date = today - timedelta(days=day_index)
    op_start = case_date.replace(hour=random.randint(8, 16))
    op_end = op_start + timedelta(minutes=random.randint(60, 240))
    
    # Admission and Discharge
    admission_date = op_start - timedelta(days=random.randint(1, 2))
    discharge_date = op_end + timedelta(days=random.randint(2, 10))

    risk = 0.015 * h_data['risk']
    if 60 < day_index < 90: risk += 0.08 # æ³¢å‹•
    is_bad = random.random() < risk
    
    # Check if deceased (Numerator)
    is_deceased = False
    abnormal_reason = None
    
    # FHIR Write
    pat_id = get_long_id()
    gender = random.choice(['male', 'female'])
    pat = client.resource('Patient', id=pat_id, gender=gender)
    if is_bad: 
        death_time = op_end + timedelta(hours=random.randint(2, 46))
        pat['deceasedDateTime'] = death_time.strftime('%Y-%m-%dT%H:%M:%S+00:00')
        is_deceased = True
        abnormal_reason = "è¡“å¾Œ48å°æ™‚å…§æ­»äº¡"
    await pat.save()
    
    enc_id = get_long_id()
    enc = client.resource(
        'Encounter', id=enc_id, status='finished',
        class_={'code': 'IMP'}, subject={'reference': f"Patient/{pat_id}"},
        serviceProvider={'reference': f"Organization/{dept['org_id']}", 'display': dept['org_name']}
    )
    if is_bad: enc['hospitalization'] = {'dischargeDisposition': {'coding': [{'code': 'exp'}]}}
    await enc.save()
    
    proc_id = get_long_id()
    proc = client.resource(
        'Procedure', id=proc_id, status='completed',
        subject={'reference': f"Patient/{pat_id}"}, encounter={'reference': f"Encounter/{enc_id}"},
        performedPeriod={'end': op_end.strftime('%Y-%m-%dT%H:%M:%S+00:00')},
        code={'coding': [{'display': 'Surgery'}]},
        performer=[{'actor': {'reference': f"Practitioner/{doc_id}"}}]
    )
    await proc.save()

    # Collect Data for KPI
    # Indicator: Surgery Mortality (æ‰‹è¡“æ­»äº¡ç‡)
    KPI_DETAILS_BUFFER.append({
        "hospital": hosp_name,
        "department": dept_name,
        "doctor": doc_name,
        "indicator_name": "è¡“å¾Œ48å°æ™‚æ­»äº¡ç‡",
        "indicator_def": "æ‰‹è¡“å¾Œæ­»äº¡äººæ•¸ / æ‰‹è¡“ç¸½æ¬¡æ•¸",
        "numerator": 1 if is_deceased else 0,
        "denominator": 1,
        "value": 1 if is_deceased else 0,
        "patient_id": pat_id,
        "gender": gender,
        "abnormal": is_deceased,
        "timestamp": op_start.isoformat(),
        "status": "ç•°å¸¸" if is_deceased else "æ­£å¸¸",
        "unit": "%",
        "admission_date": admission_date.isoformat(),
        "discharge_date": discharge_date.isoformat(),
        "abnormal_reason": abnormal_reason
    })

def upsert_supabase(table, data):
    if not SUPABASE_URL or not SUPABASE_KEY:
        print(f"Skipping Supabase upload for {table}: Missing Credentials")
        return

    headers = {
        "apikey": SUPABASE_KEY,
        "Authorization": f"Bearer {SUPABASE_KEY}",
        "Content-Type": "application/json",
        "Prefer": "resolution=merge-duplicates" 
    }
    
    url = f"{SUPABASE_URL}/rest/v1/{table}"
    
    # Simple Loop upload to avoid batch limits or just send whole batch if small enough
    # Supabase REST usually handles array body as insert.
    try:
        http = urllib3.PoolManager()
        encoded_data = json.dumps(data)
        resp = http.request('POST', url, body=encoded_data, headers=headers)
        if resp.status >= 300:
             print(f"Error uploading to {table}: {resp.status} - {resp.data.decode('utf-8')}")
        else:
             print(f"Uploaded {len(data)} records to {table}")
    except Exception as e:
        print(f"Exception uploading to {table}: {e}")

async def main():
    print("ğŸš€ ç”Ÿæˆè³‡æ–™ä¸¦å»ºç«‹å¸³è™Ÿè¡¨...")
    client = AsyncFHIRClient(url=FHIR_SERVER_URL)
    infra, auth_db = await create_infrastructure(client)
    
    tasks = [generate_case(client, infra, random.randint(0, DAYS_BACK)) for _ in range(TOTAL_CASES)]
    
    # åˆ†æ‰¹åŸ·è¡Œ
    for i in range(0, len(tasks), 50):
        await asyncio.gather(*tasks[i:i+50])
        print(f"é€²åº¦: {min(i+50, TOTAL_CASES)}/{TOTAL_CASES}")

    print("\nâœ… è³‡æ–™ç”Ÿæˆå®Œç•¢ï¼è«‹è¤‡è£½ä¸‹æ–¹çš„ JSON åˆ° React å°ˆæ¡ˆä¸­ä½¿ç”¨ï¼š")
    print("="*60)
    print(json.dumps(auth_db, ensure_ascii=False, indent=2))
    print("="*60)

    # Prepare KPI Summary
    # Key: (hospital, department, doctor, indicator_name)
    summary_map = {}
    
    for row in KPI_DETAILS_BUFFER:
        key = (row['hospital'], row['department'], row['doctor'], row['indicator_name'])
        if key not in summary_map:
            summary_map[key] = {
                "hospital": row['hospital'],
                "department": row['department'],
                "doctor": row['doctor'],
                "indicator_name": row['indicator_name'],
                "indicator_def": row['indicator_def'],
                "numerator": 0,
                "denominator": 0,
                "unit": row['unit']
            }
        
        summary_map[key]['numerator'] += row['numerator']
        summary_map[key]['denominator'] += row['denominator']

    kpi_summary_list = []
    for item in summary_map.values():
        if item['denominator'] > 0:
            item['value'] = round((item['numerator'] / item['denominator']) * 100, 2)
        else:
            item['value'] = 0.0
        kpi_summary_list.append(item)

    print("\nğŸ“Š ä¸Šå‚³ KPI è³‡æ–™è‡³ Supabase...")
    # Map to table columns provided in prompt:
    # KPI: (ç§‘åˆ¥ã€é†«å¸«ã€æŒ‡æ¨™åç¨±ã€æŒ‡æ¨™å®šç¾©ã€æŒ‡æ¨™å€¼ï¼Œåˆ†å­å€¼ã€åˆ†æ¯å€¼)
    # Mapping to approximate English columns. Adjust if schema is strict chinese or specific names.
    # Assuming the user created tables with these English names or I should guess. 
    # USER PROMPT had Chinese descriptions. I'll use common english column names I'd expect.
    # If this fails, user sees 400 error and can adjust.
    
    # KPI Table Mapping
    kpi_upload = []
    for k in kpi_summary_list:
        kpi_upload.append({
            "department": k['department'],
            "doctor": k['doctor'],
            "indicator_name": k['indicator_name'],
            "indicator_def": k['indicator_def'],
            "numerator": k['numerator'],
            "denominator": k['denominator'],
            "value": k['value'],
            "unit": k['unit']
            # "hospital": k['hospital'] # If table has it
        })
    
    # KPI_Detail Table Mapping
    # (ç§‘åˆ¥ã€æŒ‡æ¨™åç¨±ã€æŒ‡æ¨™å…¬å¼ã€æŒ‡æ¨™èªªæ˜ã€æŒ‡æ¨™é¡åˆ¥ã€æŒ‡æ¨™å–®ä½ã€æŒ‡æ¨™é¡å‹ã€æŒ‡æ¨™ç‹€æ…‹ã€é†«å¸«ã€æŒ‡æ¨™å€¼ï¼Œåˆ†å­/åˆ†æ¯å€¼ï¼Œç—…æ‚£å€‹è³‡(ç—…æ‚£ä»£ç¢¼ã€å§“åˆ¥ã€ç”Ÿæ—¥ï¼ˆå¹´é½¡))
    detail_upload = []
    for d in KPI_DETAILS_BUFFER:
        detail_upload.append({
            "department": d['department'],
            "doctor": d['doctor'],
            "indicator_name": d['indicator_name'],
            "indicator_def": d['indicator_def'],
            # "formula": "...",
            # "category": "...",
            "unit": d['unit'],
            "status": d['status'], # æ­£å¸¸/ç•°å¸¸
            "value": d['value'],
            "numerator": d['numerator'],
            "denominator": d['denominator'],
            "patient_id": d['patient_id'],
            "patient_gender": d['gender'],
            # "patient_age": ...,
            "report_date": d['timestamp'],
            "admission_date": d['admission_date'],
            "discharge_date": d['discharge_date'],
            "abnormal_reason": d['abnormal_reason']
        })

    upsert_supabase("KPI", kpi_upload)
    upsert_supabase("KPI_Detail", detail_upload)

if __name__ == "__main__":
    asyncio.run(main())